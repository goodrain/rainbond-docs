---
title: Easy Fluentd, combined with Rainbond plugins market, more quicker log collection
description: This paper describes the use of Fluentd plugins in Rainbond, collecting business logs and exporting to multiple different services
slug: fluentd
image: https://static.goodrain.com/wechat/flunetd/fluentd.png
---

This paper describes the use of Fluentd plugins in Rainbond, collecting business logs and exporting to multiple different services.

Previous articles introduce the collection of plugin logs for [EFK(Kibana + ElasticSearch + Filebeat)](https://mp.weixin.qq.com/s/XCTja56IibLDlASQkdonMA).The Filebeat plugin is used to forward and centralize log data and forward them to Elasticsearch or Logstash for indexing, but Filebe used as a member of the Elastic system only.

## Fluentd

Fluentd is an open-source, distributed log collection system that can be accessed from different services, data collection logs, filtering logs and distributing them to multiple storage and processing systems.Supporting various plugins, data caching mechanisms and their own resource requirements, internal reliability and combined with other services can form an efficient and intuitive log collection platform.

## Integration structure

When collecting component logs, simply enable the Fluentd plugin in the component. This will show the following two types of：

1. Kibana + ElasticSearch + Fluentd
2. Minio + Fluentd

We make the Fluentd Rainbond `general type plugins`, and after app starts, the plugin starts and automatically collects log output to multiple service sources, the entire process is non-intrusive and extensive.

![](https://static.goodrain.com/wechat/flunetd/8.png)

## Analysis of plugins

A new：**Install plugin from the Open Source Store** version of Rainbond V5.7.0, the plugin in this paper has been posted to the Open Source App Store. Use one click to install it to change the configuration file based on demand.

The Rainbond plugin system is part of the application model for Rainbond and is primarily used to support the extension of the application container.Since there is greater commonality in the delivery of the tools, the plugin itself can be reused.Plugins must be bound to the application container in order to be operational in order to achieve a performance capability such as performance analysis plugin, network governance plugin, initialization type plugin.

During the Fluentd plugin, **Generic Type Plugins** are used, which is understood to mean that a POD starts two Containers, Kubernetes supports the launch of multiple Containers in a POD, but it is relatively complex to configure and make it easier for users to operate through plugins in Rainbond

## EFK Log collection practice

Fluentd-ElasticSearch7 output plugin writes log entries to Elasticsearch.By default, it creates records using the batch API, which performs multiple indexing actions in a single API call.This reduces costs and can significantly increase indexing.

### 3.1 Steps to operate

Both apps (Kibana + ElasticSearch) and plugins (Fluentd) can be deployed through an open source store by one key.

1. Interface the Open Source App Store
2. Search for `elasticsearch` in the app store and install version `7.15.2`.
3. Team View -> Plugin -> Install `Fluentd-ElasticSearch7` from the App Store
4. Build components based on mirrors, using `nginx:` and mount the `var/log/nginx` storage.Use `Nginx:latest` here as a demonstration
   - Once the memory is mounted inside the component, the plugin will also automatically mount the storage and access the log file generated by Nginx.
5. Open plugins in the Nginx component, you can modify the `Fluentd` configuration as required, and refer to the profile section below.

![](https://static.goodrain.com/wechat/flunetd/2.png)

6. Add ElasticSearch dependence, connect Nginx to ElasticSearch, for example with：

![](https://static.goodrain.com/wechat/flunetd/3.png)

7. Visit the `Kibana` panel, go to Stack Management -> Data -> Indexes, see existing indexes called `influentd.es.nginx.log`,

8. Visit the `Kibana` panel, go to Stack Management -> Kibana -> Index mode to create an index mode.

9. Go to Discover, log display properly.

![](https://static.goodrain.com/wechat/flunetd/4.png)

### 3.2 Introduction to configuration files

The configuration file refers to Fluentd document [output_elasticsearch](https://docs.fluentd.org/output/elasticsearch "output_elasticsearch").

```yaml
<source>
  @type tail
  path /var/log/nginx/access.log,/var/log/nginx/error.log
  pos_file /var/log/nginx/nginx.access.log.pos
  <parse>
    @type nginx
  </parse>
  tag es.nginx.log
</source>

<match es.nginx.**>
  @type elasticsearch   
  log_level info          
  hosts 127.0.0.1
  port 9200
  user elastic
  password elastic
  index_name fluentd.${tag}
  <buffer>
    chunk_limit_size 2M
    queue_limit_length  32
    flush_interval 5s
    retry_max_times 30
  </buffer>
</match>
```

Configuration Item Explanation：

| Configuration Item            | Explanatory note                                                                                     |
| ----------------------------- | ---------------------------------------------------------------------------------------------------- |
| @type            | Getting log types, tails to read log content incrementally.                          |
| Path                          | Log paths, multiple paths can be separated by commas                                                 |
| pos_file | Path to mark the position file (position file) that has been read to the location |
| \parse \parse                 | Log format parses, write corresponding parse rules based on your own log format.     |

| Configuration Item                                           | Explanatory note                                                                                                                                           |
| ------------------------------------------------------------ | ---------------------------------------------------------------------------------------------------------------------------------------------------------- |
| @type                                           | Type of service to output                                                                                                                                  |
| log_level                               | Set the output log level to info; the supported log level is：`fatal`, `error`, `warn`, `info`, `debug`, `track`.                           |
| hosts                                                        | Address of elasticsearch                                                                                                                                   |
| Ports                                                        | Port of elasticsearch                                                                                                                                      |
| user/password                                                | Username/Password used by elasticsearch                                                                                                                    |
| index_name                              | Name defined by index.                                                                                                                     |
| \buffer\buffer                                               | The buffer of the log, used to cache log events and improve system performance.Use memory by default and file files                        |
| chunk_limit_size   | Maximum size of each block: events will be written into blocks until the size of the block becomes this size, memory will be 8M, file 256M |
| queue_limit_length | Queue length limit for this buffer plugin instance                                                                                                         |
| flush_interval                          | Buffer log refreshes events, default 60s refresh output once                                                                                               |
| retry_max_times    | Maximum number of retries failed blocks output                                                                                                             |

The above are just departmental assignment parameters, other configurations can be customized to official web documents.

## Fluentd + Minio Log collection practice

Fluentd S3 output plugin writes log entries to standard S3 object storage services such as Amazon, Minio.

### 4.1 Operational steps

Both apps (Minio) and plugins (Fluentd S3) can be deployed on one click through the Open Source App Store.

1. Open source store to connect.Search for `minio` in the open source store and install version `22.06.17`.

2. Team View -> Plugin -> Install the `Fluentd-S3` plugin from the App Store.

3. Visit Minio 9090 port. User passwords are fetched in Minio Component -> Dependencies.

   - Create Bucket, custom name.

   - Enter Configurations -> Region, set Service Location
     - `s3_region` defaults to `en-test-test2` in the Fluentd plugin configuration.

4. Build components based on mirrors, using `nginx:` and mount the `var/log/nginx` storage.Use `Nginx:latest` here as a demonstration

   - Once the memory is mounted inside the component, the plugin will also automatically mount the storage and access the log file generated by Nginx.

5. Go to the Nginx component, enable Fluentd S3 plugin, modify the `s3_bucket` `s3_region` in the configuration file.

![](https://static.goodrain.com/wechat/flunetd/5.png)

6. Create dependency, the Nginx component depends on Minio, update the component to take effect.

![](https://static.goodrain.com/wechat/flunetd/6.png)

7. Visit the Nginx service to create a log that will be visible in the Bucket of Minio.

![](https://static.goodrain.com/wechat/flunetd/7.png)

### 4.2 Introduction to configuration file

Profile refers to the Fluentd document [Apache to Minio](https://docs.fluentd.org/how-to-guides/apache-to-minio "Apache to Minio").

```yaml
<source>
  @type tail
  path /var/log/nginx/access.log
  pos_file /var/log/nginx/nginx.access.log.pos
  tag minio.nginx.access
  <parse>
    @type nginx
  </parse>
</source>

<match minio.nginx.**>
  @type s3        
  aws_key_id "#{ENV['MINIO_ROOT_USER']}"
  aws_sec_key "#{ENV['MINIO_ROOT_PASSWORD']}"
  s3_endpoint http://127.0.0.1:9000/
  s3_bucket test
  s3_region en-west-test2
  time_slice_format %Y%m%d%H%M 
  force_path_style true
  path logs/
  <buffer time>
    @type file
    path /var/log/nginx/s3
    timekey 1m                 
    timekey_wait 10s            
    chunk_limit_size 256m       
  </buffer>
</match>
```

Configuration Item Explanation：

| Configuration Item            | Explanatory note                                                                                     |
| ----------------------------- | ---------------------------------------------------------------------------------------------------- |
| @type            | Getting log types, tails to read log content incrementally.                          |
| Path                          | Log paths, multiple paths can be separated by commas                                                 |
| pos_file | Path to mark the position file (position file) that has been read to the location |
| \parse\parse                  | Log format parses, write corresponding parse rules based on your own log format.     |

| Configuration Item                                          | Explanatory note                                                                                                                    |
| ----------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------- |
| @type                                          | Type of service to output                                                                                                           |
| aws_key_id        | Minio Username                                                                                                                      |
| ws_sec_key        | Minio Password                                                                                                                      |
| s3_endpoint                            | Minio Access Address                                                                                                                |
| s3_bucket                              | Minio drum name                                                                                                                     |
| force_path_style  | Prevent AWS SDK break-endpoint URL                                                                                                  |
| time_slice_format | Add this timestamp to each filename                                                                                                 |
| \buffer\buffer                                              | The buffer of the log, used to cache log events and improve system performance.Use memory by default and file files |
| timekey                                                     | Refresh cumulative chunk every 60 seconds                                                                                           |
| timekey_wait                           | Waiting for 10 seconds to refresh                                                                                                   |
| chunk_limit_size  | Maximum size per block                                                                                                              |

## Last

Fluentd plugins can be flexible in collecting business logs and exporting to more than one service and installing one click on the Rainbond plugin market, making our use easier and faster.

Currently the Flunetd plugin on the Rainbond Open Source Plugin Marketplace only `Flinetd-S3` `Flinetd-ElasticSearch7`. Welcome small partners to contribute!
